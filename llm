from langchain.chat_models import ChatOllama
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

chat_model = ChatOllama(
    model="llava",
    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),

)
from langchain.schema import HumanMessage

messages = [HumanMessage(content="what is this? /home/ludi/DSC00779.jpg")]
chat_model(messages)
